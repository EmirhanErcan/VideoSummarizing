{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torch.__version__\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30beac26",
   "metadata": {},
   "source": [
    "# Detect, track and count Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23349aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd C:/Users/TR/Documents/GitHub/Tracking-and-counting-Using-YOLOv8-and-DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c7b6e",
   "metadata": {},
   "source": [
    "# DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort.utils.parser import get_config\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from deep_sort.sort.tracker import Tracker\n",
    "\n",
    "deep_sort_weights = 'deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the video path\n",
    "video_path = 'securitycam.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output5.avi'\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "frames = []\n",
    "\n",
    "unique_track_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "detection_start_time = None  # Time göstergesi için ekledim\n",
    "track_detection_times = {} # NEW1\n",
    "\n",
    "\n",
    "def frame_contains_humans(frame, min_confidence=0.5):\n",
    "    # Detect humans in the frame using your YOLO model\n",
    "    results = model(frame, classes=0, conf=min_confidence)\n",
    "    \n",
    "    # Check if any bounding boxes are detected\n",
    "    if isinstance(results, list):\n",
    "        for result in results:\n",
    "            if len(result.boxes.xyxy) > 0:\n",
    "                return True\n",
    "    else:\n",
    "        if len(results.boxes.xyxy) > 0:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "\n",
    "    og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # frame = og_frame.copy() saat 18:33 27.04.2024\n",
    "\n",
    "    \n",
    "    results = model(frame, classes=0, conf=0.5)\n",
    "\n",
    "    if detection_start_time is None:  # Time göstergesi için ekledim\n",
    "        detection_start_time = time.perf_counter()  # Time göstergesi için ekledim\n",
    "\n",
    "    current_time = time.perf_counter() # NEW1\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        conf = boxes.conf\n",
    "        xywh = boxes.xywh.cpu().numpy()  # box with xywh format, (N, 4)\n",
    "        bboxes_xywh = np.array(xywh, dtype=float)\n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "\n",
    "\n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "\n",
    "            if track_id not in track_detection_times: # NEW1\n",
    "                track_detection_times[track_id] = current_time # NEW1\n",
    "\n",
    "            detection_time = track_detection_times[track_id] # NEW1\n",
    "\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"Person-{track_id} ({detection_time - detection_start_time:.1f}s)\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            # unique_track_ids.add(track_id)\n",
    "\n",
    "   \n",
    "\n",
    "    # Update FPS and place on frame\n",
    "    # current_time = time.perf_counter() satırını yukarı aldım\n",
    "    \n",
    "    # Append the frame to the list\n",
    "    # frames.append(og_frame) saat 18:33 27.04.2024\n",
    "\n",
    "    # Write the frame to the output video file\n",
    "    if frame_contains_humans(frame):\n",
    "         out.write(cv2.cvtColor(og_frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Show the frame\n",
    "    #cv2.imshow(\"Video\", og_frame)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #   break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3bae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
